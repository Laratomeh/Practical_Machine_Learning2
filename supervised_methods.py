# -*- coding: utf-8 -*-
"""Supervised_methods.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D7Me3as-piE5D0r0xsrb9LreKje_kq4S

# Importing Libraries
"""
!pip install wordcloud
# !pip install dataprep
# !pip install -U dataprep
# !from dataprep.eda import *

# Commented out IPython magic to ensure Python compatibility.
!pip install contractions
# %matplotlib inline
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
import re
import contractions
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('punkt')
nltk.download('words')
from nltk.corpus import stopwords
from sklearn.feature_extraction import text
from sklearn.cluster import KMeans,MiniBatchKMeans
from nltk.tokenize import RegexpTokenizer
from nltk.stem.snowball import SnowballStemmer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from wordcloud import WordCloud,STOPWORDS
from nltk.tokenize import word_tokenize,sent_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.svm import SVC,LinearSVC 
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score
from sklearn.model_selection import train_test_split
from string import punctuation
from nltk import pos_tag
from nltk.corpus import wordnet
import string
import matplotlib.cm as cm
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA

"""# Importing & Analyzing Data"""

df = pd.read_csv("/content/fake_job_postings.csv",engine='python',header=0,error_bad_lines=False)

# create_report(df)

df.head()

df.describe()

df.info()

df.shape

df.isna().sum()

unique = df.nunique()
print("Number of unique values:\n{}".format(unique))

df.groupby('fraudulent').describe()

fig1, ax1 = plt.subplots(figsize=(10,6))
colors = plt.get_cmap('Greens')(np.linspace(0.2, 0.7, len(df['fraudulent'])))
ax1.pie(df['fraudulent'].value_counts(),colors=colors, explode=(0,0.1),labels=['Not fraudulent','fraudulent'],autopct='%1.1f%%')
ax1.axis('equal')  
plt.tight_layout()
plt.legend()
plt.show()

plt.figure(figsize = (10,10))
correlation = df.corr()
sns.heatmap(correlation,cmap= "Pastel1_r")

df.head()

"""# Data Preprocessing"""

del df['telecommuting']
del df['has_company_logo']
del df['has_questions']

fraud = df[df['fraudulent']== 1]
fraud.shape

not_fraud = df[df['fraudulent']== 0]
not_fraud.shape

df.fillna(" ",inplace = True)

df.isna().sum()

df['full_text'] = df['title'] + ' ' + df['location'] + ' ' + df['department'] + ' ' + df['company_profile'] + ' ' + df['description'] + ' ' + df['requirements'] + ' ' + df['benefits'] + ' ' + df['employment_type'] + ' ' +df['required_experience'] + ' ' + df['required_education'] + ' ' + df['industry'] + ' ' + df['function']

df.full_text[0]

df.head()

df[df['full_text'].duplicated(keep=False)].sort_values('full_text').head()

df = df.drop_duplicates('full_text')

df.shape

del df['title']
del df['location']
del df['department']
del df['company_profile']
del df['description']
del df['requirements']
del df['benefits']
del df['employment_type']
del df['required_experience']
del df['required_education']
del df['industry']
del df['function']
del df['salary_range']
del df['job_id']

df.head()

df.full_text

# Define a function to clean up the text
REPLACE_BRACKETS = re.compile('[/(){}\[\]\|@,;]')
REMOVE_NUMBERS = re.compile('[\d+]')
REMOVE_SYMBOLS = re.compile('[^0-9a-z #+_]')
STOPWORDS = set(stopwords.words('english'))
words = set(nltk.corpus.words.words())

def clean(text):
    # convert text to lowercase
    text = text.lower() 

    # replace brackets by blank space
    text = REPLACE_BRACKETS.sub(' ', text) 
    
    # get rid of numbers
    text = REMOVE_NUMBERS.sub('', text)

    # get rid of symbols
    text = REMOVE_SYMBOLS.sub('', text) 
    
    # Removing contractions "abbreviations"
    text = contractions.fix(text)

    # get rid of stopwords
    text = ' '.join(word for word in text.split() if word not in STOPWORDS) 
    
    # get rid of any words consist of 2 or more than 21 letters
    text = ' '.join(word for word in text.split() if (len(word) >= 3 and len(word) <= 21))

    # get rid of any word which is not in English dictionary
    text = " ".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in words or not w.isalpha())

    # # Stemming words
    # stemmer = PorterStemmer()
    # text = ' '.join([stemmer.stem(word) for word in text.split()])

    # Lemmatizing words
    lemmatizer = WordNetLemmatizer()
    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])
    
    return text

df["full_text"] = df["full_text"].apply(clean)
df["full_text"]

# plt.figure(figsize = (20,20)) # Text that is not fraudulent(0)
# wc = WordCloud(width = 1600 , height = 800,  background_color ='white' , max_words = 500).generate(" ".join(df[df.fraudulent == 0].lower_text))
# plt.imshow(wc , interpolation = 'bilinear')

# plt.figure(figsize = (20,20)) # Text that is fraudulent(1)
# wc = WordCloud(width = 1600 , height = 800 , max_words = 500).generate(" ".join(df[df.fraudulent == 1].lower_text))
# plt.imshow(wc , interpolation = 'bilinear')

"""# Support Vector Machine - Attempt 1 

"""

train_text , test_text ,train_category , test_category = train_test_split(df.full_text,df.fraudulent , test_size = 0.2 , random_state = 0)

cv=CountVectorizer(min_df=1,binary=False,ngram_range=(1,1))
#transformed train reviews
cv_train_reviews=cv.fit_transform(train_text)
#transformed test reviews
cv_test_reviews=cv.transform(test_text)
print('BOW_cv_train:',cv_train_reviews.shape)
print('BOW_cv_test:',cv_test_reviews.shape)

tv=TfidfVectorizer(min_df=1,use_idf=True,ngram_range=(1,1))
#transformed train reviews
tv_train_reviews=tv.fit_transform(train_text)
#transformed test reviews
tv_test_reviews=tv.transform(test_text)
print('Tfidf_train:',tv_train_reviews.shape)
print('Tfidf_test:',tv_test_reviews.shape)

#training the model
svc=LinearSVC()
#fitting the svc for bag of words
svc_bow=svc.fit(cv_train_reviews,train_category)
print(svc_bow)
#fitting the svc for tfidf features
svc_tfidf=svc.fit(tv_train_reviews,train_category)
print(svc_tfidf)

#Predicting the model for bag of words
svc_bow_predict=svc.predict(cv_test_reviews)
#Predicting the model for tfidf features
svc_tfidf_predict=svc.predict(tv_test_reviews)

#Accuracy score for bag of words
svc_bow_score=accuracy_score(test_category,svc_bow_predict)
print("svc_bow_score :",svc_bow_score)
#Accuracy score for tfidf features
svc_tfidf_score=accuracy_score(test_category,svc_tfidf_predict)
print("svc_tfidf_score :",svc_tfidf_score)

svc_bow_report = classification_report(test_category,svc_bow_predict,target_names = ['0','1'])
print(svc_bow_report)
svc_tfidf_report = classification_report(test_category,svc_tfidf_predict,target_names = ['0','1'])
print(svc_tfidf_report)

cm_cv = confusion_matrix(test_category,svc_bow_predict)
cm_tv = confusion_matrix(test_category,svc_tfidf_predict)
cm_cv , cm_tv

cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])
cm_cv.index.name = 'Actual'
cm_cv.columns.name = 'Predicted'
cm_tv = pd.DataFrame(cm_tv, index=[0,1], columns=[0,1])
cm_tv.index.name = 'Actual'
cm_tv.columns.name = 'Predicted'

plt.figure(figsize = (5,5))
sns.heatmap(cm_cv,cmap= "RdPu",annot = True, fmt='')

plt.figure(figsize = (5,5))
sns.heatmap(cm_tv,cmap= "RdPu",annot = True, fmt='')

"""# Support Vector Machine - Attempt 2"""

train_text , test_text ,train_category , test_category = train_test_split(df.full_text,df.fraudulent , test_size = 0.2 , random_state = 0)

cv=CountVectorizer(min_df=1,binary=False,ngram_range=(1,1))
#transformed train reviews
cv_train_reviews=cv.fit_transform(train_text)
#transformed test reviews
cv_test_reviews=cv.transform(test_text)
print('BOW_cv_train:',cv_train_reviews.shape)
print('BOW_cv_test:',cv_test_reviews.shape)

tv=TfidfVectorizer(min_df=1,use_idf=True,ngram_range=(1,1))
#transformed train reviews
tv_train_reviews=tv.fit_transform(train_text)
#transformed test reviews
tv_test_reviews=tv.transform(test_text)
print('Tfidf_train:',tv_train_reviews.shape)
print('Tfidf_test:',tv_test_reviews.shape)

#training the model
svc=SVC(kernel='linear')
#fitting the svc for bag of words
svc_bow=svc.fit(cv_train_reviews,train_category)
print(svc_bow)
#fitting the svc for tfidf features
svc_tfidf=svc.fit(tv_train_reviews,train_category)
print(svc_tfidf)

#Predicting the model for bag of words
svc_bow_predict=svc.predict(cv_test_reviews)
#Predicting the model for tfidf features
svc_tfidf_predict=svc.predict(tv_test_reviews)

#Accuracy score for bag of words
svc_bow_score=accuracy_score(test_category,svc_bow_predict)
print("svc_bow_score :",svc_bow_score)
#Accuracy score for tfidf features
svc_tfidf_score=accuracy_score(test_category,svc_tfidf_predict)
print("svc_tfidf_score :",svc_tfidf_score)

svc_bow_report = classification_report(test_category,svc_bow_predict,target_names = ['0','1'])
print(svc_bow_report)
svc_tfidf_report = classification_report(test_category,svc_tfidf_predict,target_names = ['0','1'])
print(svc_tfidf_report)

cm_cv = confusion_matrix(test_category,svc_bow_predict)
cm_tv = confusion_matrix(test_category,svc_tfidf_predict)
cm_cv , cm_tv

cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])
cm_cv.index.name = 'Actual'
cm_cv.columns.name = 'Predicted'
cm_tv = pd.DataFrame(cm_tv, index=[0,1], columns=[0,1])
cm_tv.index.name = 'Actual'
cm_tv.columns.name = 'Predicted'

plt.figure(figsize = (5,5))
sns.heatmap(cm_cv,cmap= "RdPu",annot = True, fmt='')

plt.figure(figsize = (5,5))
sns.heatmap(cm_tv,cmap= "RdPu",annot = True, fmt='')

"""# Support Vector Machine - Attempt 3

Stem **
"""

train_text , test_text ,train_category , test_category = train_test_split(df.full_text,df.fraudulent , test_size = 0.2 , random_state = 0)

cv=CountVectorizer(min_df=1,binary=False,ngram_range=(1,2))
#transformed train reviews
cv_train_reviews=cv.fit_transform(train_text)
#transformed test reviews
cv_test_reviews=cv.transform(test_text)
print('BOW_cv_train:',cv_train_reviews.shape)
print('BOW_cv_test:',cv_test_reviews.shape)

tv=TfidfVectorizer(min_df=1,use_idf=True,ngram_range=(1,2))
#transformed train reviews
tv_train_reviews=tv.fit_transform(train_text)
#transformed test reviews
tv_test_reviews=tv.transform(test_text)
print('Tfidf_train:',tv_train_reviews.shape)
print('Tfidf_test:',tv_test_reviews.shape)

#training the model
svc=LinearSVC(random_state=5,max_iter=500)
#fitting the svc for bag of words
svc_bow=svc.fit(cv_train_reviews,train_category)
print(svc_bow)
#fitting the svc for tfidf features
svc_tfidf=svc.fit(tv_train_reviews,train_category)
print(svc_tfidf)

#Predicting the model for bag of words
svc_bow_predict=svc.predict(cv_test_reviews)
#Predicting the model for tfidf features
svc_tfidf_predict=svc.predict(tv_test_reviews)

#Accuracy score for bag of words
svc_bow_score=accuracy_score(test_category,svc_bow_predict)
print("svc_bow_score :",svc_bow_score)
#Accuracy score for tfidf features
svc_tfidf_score=accuracy_score(test_category,svc_tfidf_predict)
print("svc_tfidf_score :",svc_tfidf_score)

svc_bow_report = classification_report(test_category,svc_bow_predict,target_names = ['0','1'])
print(svc_bow_report)
svc_tfidf_report = classification_report(test_category,svc_tfidf_predict,target_names = ['0','1'])
print(svc_tfidf_report)

cm_cv = confusion_matrix(test_category,svc_bow_predict)
cm_tv = confusion_matrix(test_category,svc_tfidf_predict)
cm_cv , cm_tv

cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])
cm_cv.index.name = 'Actual'
cm_cv.columns.name = 'Predicted'
cm_tv = pd.DataFrame(cm_tv, index=[0,1], columns=[0,1])
cm_tv.index.name = 'Actual'
cm_tv.columns.name = 'Predicted'

plt.figure(figsize = (5,5))
sns.heatmap(cm_cv,cmap= "RdPu",annot = True, fmt='')

plt.figure(figsize = (5,5))
sns.heatmap(cm_tv,cmap= "RdPu",annot = True, fmt='')

"""# Support Vector Machine - Attempt 4

Stem **
"""

train_text , test_text ,train_category , test_category = train_test_split(df.full_text,df.fraudulent , test_size = 0.4 , random_state = 0)

cv=CountVectorizer(max_df=2, min_df=1,ngram_range=(1,1))
#transformed train reviews
cv_train_reviews=cv.fit_transform(train_text)
#transformed test reviews
cv_test_reviews=cv.transform(test_text)
print('BOW_cv_train:',cv_train_reviews.shape)
print('BOW_cv_test:',cv_test_reviews.shape)

tv=TfidfVectorizer(max_df=2, min_df=1,ngram_range=(1,1))
#transformed train reviews
tv_train_reviews=tv.fit_transform(train_text)
#transformed test reviews
tv_test_reviews=tv.transform(test_text)
print('Tfidf_train:',tv_train_reviews.shape)
print('Tfidf_test:',tv_test_reviews.shape)

#training the model
svc=LinearSVC(random_state=10,fit_intercept='false',max_iter=1500)
#fitting the svc for bag of words
svc_bow=svc.fit(cv_train_reviews,train_category)
print(svc_bow)
#fitting the svc for tfidf features
svc_tfidf=svc.fit(tv_train_reviews,train_category)
print(svc_tfidf)

#Predicting the model for bag of words
svc_bow_predict=svc.predict(cv_test_reviews)
#Predicting the model for tfidf features
svc_tfidf_predict=svc.predict(tv_test_reviews)

#Accuracy score for bag of words
svc_bow_score=accuracy_score(test_category,svc_bow_predict)
print("svc_bow_score :",svc_bow_score)
#Accuracy score for tfidf features
svc_tfidf_score=accuracy_score(test_category,svc_tfidf_predict)
print("svc_tfidf_score :",svc_tfidf_score)

svc_bow_report = classification_report(test_category,svc_bow_predict,target_names = ['0','1'])
print(svc_bow_report)
svc_tfidf_report = classification_report(test_category,svc_tfidf_predict,target_names = ['0','1'])
print(svc_tfidf_report)

cm_cv = confusion_matrix(test_category,svc_bow_predict)
cm_tv = confusion_matrix(test_category,svc_tfidf_predict)
cm_cv , cm_tv

cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])
cm_cv.index.name = 'Actual'
cm_cv.columns.name = 'Predicted'
cm_tv = pd.DataFrame(cm_tv, index=[0,1], columns=[0,1])
cm_tv.index.name = 'Actual'
cm_tv.columns.name = 'Predicted'

plt.figure(figsize = (5,5))
sns.heatmap(cm_cv,cmap= "RdPu",annot = True, fmt='')

plt.figure(figsize = (5,5))
sns.heatmap(cm_tv,cmap= "RdPu",annot = True, fmt='')

"""# Decision Trees - Attempt 1 

"""

train_text , test_text ,train_category , test_category = train_test_split(df.full_text,df.fraudulent , test_size = 0.2 , random_state = 0)

cv=CountVectorizer(min_df=1,max_df=1,binary=False)
#transformed train reviews
cv_train_reviews=cv.fit_transform(train_text)
#transformed test reviews
cv_test_reviews=cv.transform(test_text)
print('BOW_cv_train:',cv_train_reviews.shape)
print('BOW_cv_test:',cv_test_reviews.shape)

tv=TfidfVectorizer(min_df=1,max_df=1,use_idf=True)
#transformed train reviews
tv_train_reviews=tv.fit_transform(train_text)
#transformed test reviews
tv_test_reviews=tv.transform(test_text)
print('Tfidf_train:',tv_train_reviews.shape)
print('Tfidf_test:',tv_test_reviews.shape)

#training the model
dtc=DecisionTreeClassifier()
#fitting the dtc for bag of words
dtc_bow=dtc.fit(cv_train_reviews,train_category)
print(dtc_bow)
#fitting the dtc for tfidf features
dtc_tfidf=dtc.fit(tv_train_reviews,train_category)
print(dtc_tfidf)

#Predicting the model for bag of words
dtc_bow_predict=dtc.predict(cv_test_reviews)
#Predicting the model for tfidf features
dtc_tfidf_predict=dtc.predict(tv_test_reviews)

#Accuracy score for bag of words
dtc_bow_score=accuracy_score(test_category,dtc_bow_predict)
print("dtc_bow_score :",dtc_bow_score)
#Accuracy score for tfidf features
dtc_tfidf_score=accuracy_score(test_category,dtc_tfidf_predict)
print("dtc_tfidf_score :",dtc_tfidf_score)

dtc_bow_report = classification_report(test_category,dtc_bow_predict,target_names = ['0','1'])
print(dtc_bow_report)
dtc_tfidf_report = classification_report(test_category,dtc_tfidf_predict,target_names = ['0','1'])
print(dtc_tfidf_report)

cm_cv = confusion_matrix(test_category,dtc_bow_predict)
cm_tv = confusion_matrix(test_category,dtc_tfidf_predict)
cm_cv , cm_tv

cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])
cm_cv.index.name = 'Actual'
cm_cv.columns.name = 'Predicted'
cm_tv = pd.DataFrame(cm_tv, index=[0,1], columns=[0,1])
cm_tv.index.name = 'Actual'
cm_tv.columns.name = 'Predicted'

plt.figure(figsize = (5,5))
sns.heatmap(cm_cv,cmap= "Greens",annot = True, fmt='')

plt.figure(figsize = (5,5))
sns.heatmap(cm_tv,cmap= "Greens",annot = True, fmt='')

"""# Decision Trees - Attempt 2


"""

train_text , test_text ,train_category , test_category = train_test_split(df.full_text,df.fraudulent , test_size = 0.3 , random_state = 0)

cv=CountVectorizer(min_df=1,max_df=1,binary=False)
#transformed train reviews
cv_train_reviews=cv.fit_transform(train_text)
#transformed test reviews
cv_test_reviews=cv.transform(test_text)
print('BOW_cv_train:',cv_train_reviews.shape)
print('BOW_cv_test:',cv_test_reviews.shape)

tv=TfidfVectorizer(min_df=1,max_df=1,use_idf=True)
#transformed train reviews
tv_train_reviews=tv.fit_transform(train_text)
#transformed test reviews
tv_test_reviews=tv.transform(test_text)
print('Tfidf_train:',tv_train_reviews.shape)
print('Tfidf_test:',tv_test_reviews.shape)

#training the model
dtc=DecisionTreeClassifier(random_state=0,splitter='random')
#fitting the dtc for bag of words
dtc_bow=dtc.fit(cv_train_reviews,train_category)
print(dtc_bow)
#fitting the dtc for tfidf features
dtc_tfidf=dtc.fit(tv_train_reviews,train_category)
print(dtc_tfidf)

#Predicting the model for bag of words
dtc_bow_predict=dtc.predict(cv_test_reviews)
#Predicting the model for tfidf features
dtc_tfidf_predict=dtc.predict(tv_test_reviews)

#Accuracy score for bag of words
dtc_bow_score=accuracy_score(test_category,dtc_bow_predict)
print("dtc_bow_score :",dtc_bow_score)
#Accuracy score for tfidf features
dtc_tfidf_score=accuracy_score(test_category,dtc_tfidf_predict)
print("dtc_tfidf_score :",dtc_tfidf_score)

dtc_bow_report = classification_report(test_category,dtc_bow_predict,target_names = ['0','1'])
print(dtc_bow_report)
dtc_tfidf_report = classification_report(test_category,dtc_tfidf_predict,target_names = ['0','1'])
print(dtc_tfidf_report)

cm_cv = confusion_matrix(test_category,dtc_bow_predict)
cm_tv = confusion_matrix(test_category,dtc_tfidf_predict)
cm_cv , cm_tv

cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])
cm_cv.index.name = 'Actual'
cm_cv.columns.name = 'Predicted'
cm_tv = pd.DataFrame(cm_tv, index=[0,1], columns=[0,1])
cm_tv.index.name = 'Actual'
cm_tv.columns.name = 'Predicted'

plt.figure(figsize = (5,5))
sns.heatmap(cm_cv,cmap= "Greens",annot = True, fmt='')

plt.figure(figsize = (5,5))
sns.heatmap(cm_tv,cmap= "Greens",annot = True, fmt='')

"""# Decision Trees - Attempt 3

Stem **
"""

train_text , test_text ,train_category , test_category = train_test_split(df.full_text,df.fraudulent , test_size = 0.2 , random_state = 0)

cv=CountVectorizer(min_df=1,max_df=1,binary=False)
#transformed train reviews
cv_train_reviews=cv.fit_transform(train_text)
#transformed test reviews
cv_test_reviews=cv.transform(test_text)
print('BOW_cv_train:',cv_train_reviews.shape)
print('BOW_cv_test:',cv_test_reviews.shape)

tv=TfidfVectorizer(min_df=1,max_df=1,use_idf=True)
#transformed train reviews
tv_train_reviews=tv.fit_transform(train_text)
#transformed test reviews
tv_test_reviews=tv.transform(test_text)
print('Tfidf_train:',tv_train_reviews.shape)
print('Tfidf_test:',tv_test_reviews.shape)

#training the model
dtc=DecisionTreeClassifier()
#fitting the dtc for bag of words
dtc_bow=dtc.fit(cv_train_reviews,train_category)
print(dtc_bow)
#fitting the dtc for tfidf features
dtc_tfidf=dtc.fit(tv_train_reviews,train_category)
print(dtc_tfidf)

#Predicting the model for bag of words
dtc_bow_predict=dtc.predict(cv_test_reviews)
#Predicting the model for tfidf features
dtc_tfidf_predict=dtc.predict(tv_test_reviews)

#Accuracy score for bag of words
dtc_bow_score=accuracy_score(test_category,dtc_bow_predict)
print("dtc_bow_score :",dtc_bow_score)
#Accuracy score for tfidf features
dtc_tfidf_score=accuracy_score(test_category,dtc_tfidf_predict)
print("dtc_tfidf_score :",dtc_tfidf_score)

dtc_bow_report = classification_report(test_category,dtc_bow_predict,target_names = ['0','1'])
print(dtc_bow_report)
dtc_tfidf_report = classification_report(test_category,dtc_tfidf_predict,target_names = ['0','1'])
print(dtc_tfidf_report)

cm_cv = confusion_matrix(test_category,dtc_bow_predict)
cm_tv = confusion_matrix(test_category,dtc_tfidf_predict)
cm_cv , cm_tv

cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])
cm_cv.index.name = 'Actual'
cm_cv.columns.name = 'Predicted'
cm_tv = pd.DataFrame(cm_tv, index=[0,1], columns=[0,1])
cm_tv.index.name = 'Actual'
cm_tv.columns.name = 'Predicted'

plt.figure(figsize = (5,5))
sns.heatmap(cm_cv,cmap= "Greens",annot = True, fmt='')

plt.figure(figsize = (5,5))
sns.heatmap(cm_tv,cmap= "Greens",annot = True, fmt='')

"""# Decision Trees - Attempt 4

Stem **
"""

train_text , test_text ,train_category , test_category = train_test_split(df.full_text,df.fraudulent , test_size = 0.2 , random_state = 0)

cv=CountVectorizer(ngram_range=(1,2))
#transformed train reviews
cv_train_reviews=cv.fit_transform(train_text)
#transformed test reviews
cv_test_reviews=cv.transform(test_text)
print('BOW_cv_train:',cv_train_reviews.shape)
print('BOW_cv_test:',cv_test_reviews.shape)

tv=TfidfVectorizer(ngram_range=(1,2))
#transformed train reviews
tv_train_reviews=tv.fit_transform(train_text)
#transformed test reviews
tv_test_reviews=tv.transform(test_text)
print('Tfidf_train:',tv_train_reviews.shape)
print('Tfidf_test:',tv_test_reviews.shape)

#training the model
dtc=DecisionTreeClassifier(criterion='entropy',splitter='random')
#fitting the dtc for bag of words
dtc_bow=dtc.fit(cv_train_reviews,train_category)
print(dtc_bow)
#fitting the dtc for tfidf features
dtc_tfidf=dtc.fit(tv_train_reviews,train_category)
print(dtc_tfidf)

#Predicting the model for bag of words
dtc_bow_predict=dtc.predict(cv_test_reviews)
#Predicting the model for tfidf features
dtc_tfidf_predict=dtc.predict(tv_test_reviews)

#Accuracy score for bag of words
dtc_bow_score=accuracy_score(test_category,dtc_bow_predict)
print("dtc_bow_score :",dtc_bow_score)
#Accuracy score for tfidf features
dtc_tfidf_score=accuracy_score(test_category,dtc_tfidf_predict)
print("dtc_tfidf_score :",dtc_tfidf_score)

dtc_bow_report = classification_report(test_category,dtc_bow_predict,target_names = ['0','1'])
print(dtc_bow_report)
dtc_tfidf_report = classification_report(test_category,dtc_tfidf_predict,target_names = ['0','1'])
print(dtc_tfidf_report)

cm_cv = confusion_matrix(test_category,dtc_bow_predict)
cm_tv = confusion_matrix(test_category,dtc_tfidf_predict)
cm_cv , cm_tv

cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])
cm_cv.index.name = 'Actual'
cm_cv.columns.name = 'Predicted'
cm_tv = pd.DataFrame(cm_tv, index=[0,1], columns=[0,1])
cm_tv.index.name = 'Actual'
cm_tv.columns.name = 'Predicted'

plt.figure(figsize = (5,5))
sns.heatmap(cm_cv,cmap= "Greens",annot = True, fmt='')

plt.figure(figsize = (5,5))
sns.heatmap(cm_tv,cmap= "Greens",annot = True, fmt='')